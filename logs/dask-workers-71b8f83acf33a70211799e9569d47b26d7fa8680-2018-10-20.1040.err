distributed.nanny - INFO -         Start Nanny at: 'tcp://129.129.222.109:35756'
WARNING:bokeh.server.util:Host wildcard '*' will allow connections originating from multiple (or possibly all) hostnames or IPs. Use non-wildcard values to restrict access explicitly
distributed.worker - INFO -       Start worker at: tcp://129.129.222.109:40654
distributed.worker - INFO -          Listening to: tcp://129.129.222.109:40654
distributed.worker - INFO -              nanny at:      129.129.222.109:35756
distributed.worker - INFO -               http at:      129.129.222.109:39537
distributed.worker - INFO -              bokeh at:       129.129.222.109:8789
distributed.worker - INFO - Waiting to connect to: tcp://sf-cn-1.psi.ch:34628
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.50 GB
distributed.worker - INFO -       Local Directory: /photonics/home/lemke_h/mypy/escape-fel/slurmified_files/worker-spp85it1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://sf-cn-1.psi.ch:34628
distributed.worker - INFO - -------------------------------------------------
distributed.core - WARNING - Event loop was unresponsive for 1.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.protocol.pickle - INFO - Failed to serialize dask.array<sum-aggregate, shape=(10,), dtype=float64, chunksize=(10,)>. Exception: can't pickle h5py.h5d.DatasetID objects
distributed.protocol.core - CRITICAL - Failed to Serialize
Traceback (most recent call last):
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: can't pickle h5py.h5d.DatasetID objects

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/core.py", line 44, in dumps
    for key, value in data.items()
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/core.py", line 45, in <dictcomp>
    if type(value) is Serialize}
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/serialize.py", line 138, in serialize
    header, frames = {}, [pickle.dumps(x)]
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 900, in dumps
    cp.dump(obj)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 234, in dump
    return Pickler.dump(self, obj)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 409, in dump
    self.save(obj)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 521, in save
    self.save_reduce(obj=obj, *rv)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 768, in save_reduce
    save(args)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 751, in save_tuple
    save(element)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 521, in save
    self.save_reduce(obj=obj, *rv)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 786, in save_reduce
    save(state)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 821, in save_dict
    self._batch_setitems(obj.items())
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 852, in _batch_setitems
    save(v)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 821, in save_dict
    self._batch_setitems(obj.items())
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 847, in _batch_setitems
    save(v)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 821, in save_dict
    self._batch_setitems(obj.items())
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 847, in _batch_setitems
    save(v)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 521, in save
    self.save_reduce(obj=obj, *rv)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 786, in save_reduce
    save(state)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 821, in save_dict
    self._batch_setitems(obj.items())
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 847, in _batch_setitems
    save(v)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 496, in save
    rv = reduce(self.proto)
TypeError: can't pickle h5py.h5d.DatasetID objects
distributed.comm.utils - INFO - Unserializable Message: {"('getJF-sum-sum-aggregate-20c4c8e4cfb5fb3347d14a9083c9434e', 1100)": <Serialize: dask.array<sum-aggregate, shape=(10,), dtype=float64, chunksize=(10,)>>}
distributed.comm.utils - ERROR - can't pickle h5py.h5d.DatasetID objects
Traceback (most recent call last):
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: can't pickle h5py.h5d.DatasetID objects

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/comm/utils.py", line 38, in _to_frames
    return list(protocol.dumps(msg))
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/core.py", line 44, in dumps
    for key, value in data.items()
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/core.py", line 45, in <dictcomp>
    if type(value) is Serialize}
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/serialize.py", line 138, in serialize
    header, frames = {}, [pickle.dumps(x)]
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 900, in dumps
    cp.dump(obj)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 234, in dump
    return Pickler.dump(self, obj)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 409, in dump
    self.save(obj)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 521, in save
    self.save_reduce(obj=obj, *rv)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 768, in save_reduce
    save(args)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 751, in save_tuple
    save(element)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 521, in save
    self.save_reduce(obj=obj, *rv)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 786, in save_reduce
    save(state)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 821, in save_dict
    self._batch_setitems(obj.items())
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 852, in _batch_setitems
    save(v)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 821, in save_dict
    self._batch_setitems(obj.items())
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 847, in _batch_setitems
    save(v)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 821, in save_dict
    self._batch_setitems(obj.items())
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 847, in _batch_setitems
    save(v)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 521, in save
    self.save_reduce(obj=obj, *rv)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 786, in save_reduce
    save(state)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 821, in save_dict
    self._batch_setitems(obj.items())
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 847, in _batch_setitems
    save(v)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 496, in save
    rv = reduce(self.proto)
TypeError: can't pickle h5py.h5d.DatasetID objects
distributed.core - ERROR - can't pickle h5py.h5d.DatasetID objects
Traceback (most recent call last):
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/pickle.py", line 38, in dumps
    result = pickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
TypeError: can't pickle h5py.h5d.DatasetID objects

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/core.py", line 277, in handle_comm
    result = yield result
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/tornado/gen.py", line 1055, in run
    value = future.result()
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/tornado/concurrent.py", line 238, in result
    raise_exc_info(self._exc_info)
  File "<string>", line 4, in raise_exc_info
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/tornado/gen.py", line 1063, in run
    yielded = self.gen.throw(*exc_info)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/worker.py", line 476, in get_data
    compressed = yield comm.write(msg)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/tornado/gen.py", line 1055, in run
    value = future.result()
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/tornado/concurrent.py", line 238, in result
    raise_exc_info(self._exc_info)
  File "<string>", line 4, in raise_exc_info
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/tornado/gen.py", line 1063, in run
    yielded = self.gen.throw(*exc_info)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/comm/tcp.py", line 201, in write
    frames = yield to_frames(msg)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/tornado/gen.py", line 1055, in run
    value = future.result()
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/tornado/concurrent.py", line 238, in result
    raise_exc_info(self._exc_info)
  File "<string>", line 4, in raise_exc_info
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/tornado/gen.py", line 307, in wrapper
    yielded = next(result)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/comm/utils.py", line 47, in to_frames
    res = _to_frames()
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/comm/utils.py", line 38, in _to_frames
    return list(protocol.dumps(msg))
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/core.py", line 44, in dumps
    for key, value in data.items()
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/core.py", line 45, in <dictcomp>
    if type(value) is Serialize}
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/serialize.py", line 138, in serialize
    header, frames = {}, [pickle.dumps(x)]
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/distributed/protocol/pickle.py", line 51, in dumps
    return cloudpickle.dumps(x, protocol=pickle.HIGHEST_PROTOCOL)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 900, in dumps
    cp.dump(obj)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 234, in dump
    return Pickler.dump(self, obj)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 409, in dump
    self.save(obj)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 521, in save
    self.save_reduce(obj=obj, *rv)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 768, in save_reduce
    save(args)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 751, in save_tuple
    save(element)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 521, in save
    self.save_reduce(obj=obj, *rv)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 786, in save_reduce
    save(state)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 821, in save_dict
    self._batch_setitems(obj.items())
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 852, in _batch_setitems
    save(v)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 821, in save_dict
    self._batch_setitems(obj.items())
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 847, in _batch_setitems
    save(v)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 821, in save_dict
    self._batch_setitems(obj.items())
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 847, in _batch_setitems
    save(v)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 521, in save
    self.save_reduce(obj=obj, *rv)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/site-packages/cloudpickle/cloudpickle.py", line 786, in save_reduce
    save(state)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 476, in save
    f(self, obj) # Call unbound method with explicit self
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 821, in save_dict
    self._batch_setitems(obj.items())
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 847, in _batch_setitems
    save(v)
  File "/gfa/.mounts/sf_bernina/anaconda/ahl/lib/python3.6/pickle.py", line 496, in save
    rv = reduce(self.proto)
TypeError: can't pickle h5py.h5d.DatasetID objects
distributed.core - WARNING - Event loop was unresponsive for 1.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.nanny - WARNING - Worker process 11160 was killed by unknown signal
distributed.nanny - WARNING - Restarting worker
WARNING:bokeh.server.util:Host wildcard '*' will allow connections originating from multiple (or possibly all) hostnames or IPs. Use non-wildcard values to restrict access explicitly
distributed.worker - INFO -       Start worker at: tcp://129.129.222.109:34864
distributed.worker - INFO -          Listening to: tcp://129.129.222.109:34864
distributed.worker - INFO -              nanny at:      129.129.222.109:35756
distributed.worker - INFO -               http at:      129.129.222.109:46070
distributed.worker - INFO -              bokeh at:       129.129.222.109:8789
distributed.worker - INFO - Waiting to connect to: tcp://sf-cn-1.psi.ch:34628
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -                Memory:                    4.50 GB
distributed.worker - INFO -       Local Directory: /photonics/home/lemke_h/mypy/escape-fel/slurmified_files/worker-e5nvtn12
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to: tcp://sf-cn-1.psi.ch:34628
distributed.worker - INFO - -------------------------------------------------
slurmstepd: error: *** JOB 1040 ON sf-cn-9 CANCELLED AT 2018-10-21T20:34:00 DUE TO TIME LIMIT ***
slurmstepd: error: Exceeded step memory limit at some point.
